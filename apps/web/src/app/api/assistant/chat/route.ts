/**
 * AI åŠ©æ‰‹èŠå¤© API
 *
 * POST /api/assistant/chat
 */

import { NextRequest, NextResponse } from 'next/server'
import { createClient } from '@/lib/supabase-server'
import {
  createAIClient,
  isAnyAIConfigured,
  getBestModel,
  TEMPERATURE_PRESETS,
} from '@/lib/ai-providers'
import {
  ASSISTANT_CHAT_SYSTEM_PROMPT,
  formatContextForChat,
  parseAssistantChatOutput,
} from '@/lib/ai/prompts/features/assistant-chat'
import type { PromptContext } from '@/lib/ai/prompts/types'

interface ChatRequestBody {
  message: string
  sessionId?: string
  context?: Partial<PromptContext>
}

export async function POST(request: NextRequest) {
  try {
    const supabase = await createClient()

    // æ£€æŸ¥è®¤è¯
    const {
      data: { user },
    } = await supabase.auth.getUser()

    if (!user) {
      return NextResponse.json({ error: 'è¯·å…ˆç™»å½•' }, { status: 401 })
    }

    // æ£€æŸ¥AIé…ç½®
    if (!isAnyAIConfigured()) {
      return NextResponse.json(
        {
          error: 'AIæœåŠ¡æœªé…ç½®',
          hint: 'è¯·åœ¨ç¯å¢ƒå˜é‡ä¸­é…ç½®AI APIå¯†é’¥',
        },
        { status: 503 }
      )
    }

    // è§£æè¯·æ±‚
    const body = (await request.json()) as ChatRequestBody
    const { message, context } = body

    if (!message || !message.trim()) {
      return NextResponse.json({ error: 'æ¶ˆæ¯ä¸èƒ½ä¸ºç©º' }, { status: 400 })
    }

    console.log('ğŸ¤– Processing assistant chat request...')
    console.log(`ğŸ“ Message: ${message.substring(0, 100)}...`)

    // æ„å»ºä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
    const contextStr = context
      ? formatContextForChat(context as PromptContext)
      : 'æ— ä¸Šä¸‹æ–‡ä¿¡æ¯'

    // æ„å»ºç”¨æˆ·æç¤º
    const userPrompt = `## å½“å‰ä¸Šä¸‹æ–‡

${contextStr}

## ç”¨æˆ·æ¶ˆæ¯

${message}

---

è¯·æ ¹æ®ä¸Šä¸‹æ–‡å’Œç”¨æˆ·æ¶ˆæ¯ï¼Œæä¾›æœ‰å¸®åŠ©çš„å›å¤ã€‚

å¦‚æœç”¨æˆ·çš„è¯·æ±‚éœ€è¦æ‰§è¡Œç‰¹å®šæ“ä½œï¼Œè¯·åœ¨actionsä¸­æä¾›ç›¸åº”çš„æŒ‰é’®ã€‚
å¦‚æœä½ è®¤ä¸ºæœ‰æ›´å¥½çš„åç»­é—®é¢˜ï¼Œè¯·åœ¨suggestionsä¸­æä¾›ã€‚

è¿”å›JSONæ ¼å¼ï¼ˆä¸è¦ç”¨markdownä»£ç å—åŒ…è£¹ï¼‰ï¼š
{
  "content": "Markdownæ ¼å¼çš„å›å¤å†…å®¹",
  "actions": [
    {
      "type": "navigate|execute|show_modal|confirm",
      "target": "ç›®æ ‡URLæˆ–æ“ä½œæ ‡è¯†",
      "label": "æŒ‰é’®æ˜¾ç¤ºæ–‡å­—"
    }
  ],
  "suggestions": ["å»ºè®®é—®é¢˜1", "å»ºè®®é—®é¢˜2"],
  "metadata": {
    "intent": "è¯†åˆ«åˆ°çš„æ„å›¾ç±»å‹"
  }
}`

    // è°ƒç”¨AI
    const aiClient = createAIClient()
    const model = getBestModel()

    console.log(`ğŸ“Š Using model: ${model}`)

    const completion = await aiClient.chat.completions.create({
      model,
      messages: [
        {
          role: 'system',
          content: ASSISTANT_CHAT_SYSTEM_PROMPT,
        },
        {
          role: 'user',
          content: userPrompt,
        },
      ],
      temperature: TEMPERATURE_PRESETS.CONVERSATIONAL,
      max_tokens: 2000,
    })

    const responseText = completion.choices[0]?.message?.content || ''
    console.log(`ğŸ“ AI response length: ${responseText.length}`)

    // è§£æå“åº”
    const parsed = parseAssistantChatOutput(responseText)

    if (!parsed) {
      console.error('âŒ Failed to parse AI response')
      return NextResponse.json({
        content: responseText,
        actions: [],
        suggestions: [],
        metadata: {},
      })
    }

    console.log('âœ… Successfully processed assistant chat')

    return NextResponse.json({
      content: parsed.content,
      actions: parsed.actions || [],
      suggestions: parsed.suggestions || [],
      metadata: parsed.metadata || {},
    })
  } catch (error) {
    console.error('Error in POST /api/assistant/chat:', error)
    return NextResponse.json(
      { error: 'å¤„ç†è¯·æ±‚æ—¶å‡ºé”™ï¼Œè¯·é‡è¯•' },
      { status: 500 }
    )
  }
}
