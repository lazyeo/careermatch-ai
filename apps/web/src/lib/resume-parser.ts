/**
 * ç®€å†è§£æå™¨
 *
 * ä½¿ç”¨AIä»PDF/Word/Textæ–‡ä»¶ä¸­ä¸»åŠ¨æŒ–æ˜æ‰€æœ‰æœ‰ä»·å€¼çš„ä¿¡æ¯
 */

import OpenAI from 'openai'
import type { ParsedResumeData, SkillLevel } from '@careermatch/shared'

// æ”¹è¿›çš„è§£æPrompt - ä¸»åŠ¨æŒ–æ˜æ‰€æœ‰æœ‰ä»·å€¼ä¿¡æ¯
const PARSE_PROMPT = `ä½ æ˜¯ä¸“ä¸šçš„ç®€å†è§£æä¸“å®¶å’ŒèŒä¸šé¡¾é—®ã€‚ä½ çš„ä»»åŠ¡æ˜¯ä»ç®€å†ä¸­**ä¸»åŠ¨æŒ–æ˜**æ‰€æœ‰æœ‰ä»·å€¼çš„ä¿¡æ¯ã€‚

## æ ¸å¿ƒåŸåˆ™
1. **ä¸»åŠ¨æŒ–æ˜**ï¼šä¸è¦è¢«åŠ¨ç­‰å¾…ä¿¡æ¯å‡ºç°ï¼Œè¦ä¸»åŠ¨è¯†åˆ«ç®€å†ä¸­çš„æ¯ä¸€ä¸ªæœ‰ä»·å€¼çš„ç»†èŠ‚
2. **ä¿¡æ¯å®Œæ•´æ€§**ï¼šå³ä½¿æ˜¯éšå«çš„ã€ä¸æ˜æ˜¾çš„ä¿¡æ¯ä¹Ÿè¦å°è¯•æå–
3. **çµæ´»æ‰©å±•**ï¼šå¯¹äºæ ‡å‡†å­—æ®µä¹‹å¤–çš„ä¿¡æ¯ï¼Œä½¿ç”¨ extended_data å­—æ®µä¿å­˜

## æå–æŒ‡ä»¤
1. **åŸºæœ¬ä¿¡æ¯**ï¼šå§“åã€è”ç³»æ–¹å¼ã€ç¤¾äº¤é“¾æ¥ã€æ‰€åœ¨åœ°ç­‰
2. **èŒä¸šç»å†**ï¼šå®Œæ•´æå–æ¯ä»½å·¥ä½œçš„å…¬å¸ã€èŒä½ã€æ—¶é—´ã€èŒè´£ã€æˆå°±ã€ä½¿ç”¨çš„æŠ€æœ¯
3. **æ•™è‚²èƒŒæ™¯**ï¼šå­¦æ ¡ã€å­¦ä½ã€ä¸“ä¸šã€æ—¶é—´ã€GPAã€è£èª‰å¥–é¡¹
4. **æŠ€èƒ½æ¸…å•**ï¼šä¸»åŠ¨è¯†åˆ«æŠ€æœ¯æŠ€èƒ½ã€è½¯æŠ€èƒ½ã€è¯­è¨€èƒ½åŠ›ã€å·¥å…·ç†Ÿç»ƒåº¦
5. **é¡¹ç›®ç»å†**ï¼šé¡¹ç›®åç§°ã€æè¿°ã€è§’è‰²ã€æŠ€æœ¯æ ˆã€æˆæœäº®ç‚¹
6. **è¯ä¹¦èµ„è´¨**ï¼šè¯ä¹¦åç§°ã€é¢å‘æœºæ„ã€æœ‰æ•ˆæœŸ
7. **å…¶ä»–æœ‰ä»·å€¼ä¿¡æ¯**ï¼š
   - å¿—æ„¿è€…ç»å†ã€ç¤¾åŒºè´¡çŒ®
   - å‘è¡¨çš„æ–‡ç« ã€æ¼”è®²ã€ä¸“åˆ©
   - å…´è¶£çˆ±å¥½ï¼ˆå¦‚æœä¸æ±‚èŒç›¸å…³ï¼‰
   - æ¨èäººä¿¡æ¯
   - æœŸæœ›è–ªèµ„ã€å·¥ä½œåå¥½
   - ä»»ä½•å…¶ä»–ç‹¬ç‰¹çš„ã€æœ‰ä»·å€¼çš„ä¿¡æ¯

## æ ¼å¼åŒ–è§„åˆ™
- æ—¥æœŸæ ¼å¼åŒ–ä¸º YYYY-MM-DDï¼ˆä»…æœ‰å¹´ä»½æ—¶ç”¨ YYYY-01-01ï¼‰
- "è‡³ä»Š"/"Present"/"Current" â†’ is_current=true, end_date=null
- æŠ€èƒ½åˆ†ç±»ï¼šç¼–ç¨‹è¯­è¨€ã€æ¡†æ¶ã€å·¥å…·ã€è½¯æŠ€èƒ½ã€è¯­è¨€ç­‰
- ä¿ç•™åŸå§‹æªè¾ï¼Œå°¤å…¶æ˜¯æˆå°±æè¿°

## ç®€å†å†…å®¹ï¼š
{CONTENT}

## è¾“å‡ºæ ¼å¼
è¿”å›ä¸¥æ ¼çš„JSONï¼ˆä¸è¦ç”¨markdownä»£ç å—åŒ…è£¹ï¼‰ï¼ŒåŒ…å«æ ‡å‡†å­—æ®µå’Œæ‰©å±•å­—æ®µï¼š
{
  "personal_info": {
    "full_name": "å§“å",
    "email": "é‚®ç®±",
    "phone": "ç”µè¯",
    "location": "æ‰€åœ¨åœ°",
    "linkedin_url": "LinkedIné“¾æ¥",
    "github_url": "GitHubé“¾æ¥",
    "website_url": "ä¸ªäººç½‘ç«™",
    "professional_summary": "èŒä¸šæ‘˜è¦/ä¸ªäººç®€ä»‹"
  },
  "work_experiences": [
    {
      "company": "å…¬å¸åç§°",
      "position": "èŒä½",
      "location": "å·¥ä½œåœ°ç‚¹",
      "start_date": "YYYY-MM-DD",
      "end_date": "YYYY-MM-DDæˆ–null",
      "is_current": false,
      "description": "å·¥ä½œæè¿°",
      "achievements": ["æˆå°±1", "æˆå°±2"],
      "technologies": ["æŠ€æœ¯1", "æŠ€æœ¯2"]
    }
  ],
  "education": [
    {
      "institution": "å­¦æ ¡åç§°",
      "degree": "å­¦ä½",
      "major": "ä¸“ä¸š",
      "location": "åœ°ç‚¹",
      "start_date": "YYYY-MM-DD",
      "end_date": "YYYY-MM-DDæˆ–null",
      "is_current": false,
      "gpa": 3.8,
      "achievements": ["è£èª‰/å¥–é¡¹"]
    }
  ],
  "skills": [
    {
      "name": "æŠ€èƒ½åç§°",
      "level": "beginner|intermediate|advanced|expert",
      "category": "åˆ†ç±»ï¼ˆå¦‚ï¼šç¼–ç¨‹è¯­è¨€ã€æ¡†æ¶ã€å·¥å…·ã€è½¯æŠ€èƒ½ã€è¯­è¨€ç­‰ï¼‰"
    }
  ],
  "projects": [
    {
      "name": "é¡¹ç›®åç§°",
      "description": "é¡¹ç›®æè¿°",
      "role": "è§’è‰²",
      "start_date": "YYYY-MM-DD",
      "end_date": "YYYY-MM-DD",
      "technologies": ["æŠ€æœ¯1"],
      "highlights": ["äº®ç‚¹1"],
      "url": "é¡¹ç›®é“¾æ¥",
      "github_url": "GitHubé“¾æ¥"
    }
  ],
  "certifications": [
    {
      "name": "è¯ä¹¦åç§°",
      "issuer": "é¢å‘æœºæ„",
      "issue_date": "YYYY-MM-DD",
      "expiry_date": "YYYY-MM-DDæˆ–null",
      "credential_id": "è¯ä¹¦ç¼–å·",
      "credential_url": "éªŒè¯é“¾æ¥"
    }
  ],
  "extended_data": {
    "volunteer_experience": [
      {
        "organization": "ç»„ç»‡åç§°",
        "role": "è§’è‰²",
        "period": "æ—¶é—´æ®µ",
        "description": "æè¿°"
      }
    ],
    "publications": [
      {
        "title": "æ ‡é¢˜",
        "type": "æ–‡ç« |æ¼”è®²|ä¸“åˆ©",
        "date": "æ—¥æœŸ",
        "url": "é“¾æ¥"
      }
    ],
    "languages": [
      {
        "language": "è¯­è¨€",
        "proficiency": "ç†Ÿç»ƒç¨‹åº¦"
      }
    ],
    "references": [
      {
        "name": "å§“å",
        "relationship": "å…³ç³»",
        "contact": "è”ç³»æ–¹å¼"
      }
    ],
    "preferences": {
      "expected_salary": "æœŸæœ›è–ªèµ„",
      "preferred_locations": ["åå¥½åœ°ç‚¹"],
      "job_types": ["å·¥ä½œç±»å‹åå¥½"],
      "availability": "å¯åˆ°å²—æ—¶é—´"
    },
    "additional_sections": [
      {
        "title": "éƒ¨åˆ†æ ‡é¢˜",
        "content": "æ ¼å¼åŒ–çš„å†…å®¹ï¼ˆå¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ–å¯¹è±¡ï¼‰"
      }
    ]
  }
}

æ³¨æ„ï¼š
1. extended_data ä¸­çš„å­—æ®µæ˜¯å¯é€‰çš„ï¼Œåªæœ‰åœ¨ç®€å†ä¸­å­˜åœ¨ç›¸å…³ä¿¡æ¯æ—¶æ‰éœ€è¦å¡«å†™
2. å¦‚æœæŸä¸ªå­—æ®µæ‰¾ä¸åˆ°ä¿¡æ¯ï¼Œä½¿ç”¨ç©ºå­—ç¬¦ä¸²ã€ç©ºæ•°ç»„æˆ–null
3. ä¸è¦è¿”å›markdownä»£ç å—ï¼Œç›´æ¥è¿”å›JSON`

/**
 * ä»æ–‡æœ¬å†…å®¹è§£æç®€å†
 */
export async function parseResumeContent(
  content: string,
  options?: {
    provider?: 'claude' | 'openai' | 'gemini'
    model?: string
  }
): Promise<ParsedResumeData> {
  // ä½¿ç”¨ CLAUDE_API_KEY ä¸å…¶ä»–AIåŠŸèƒ½ä¿æŒä¸€è‡´
  const apiKey = process.env.CLAUDE_API_KEY
  const baseUrl = process.env.CLAUDE_BASE_URL || 'https://relay.a-dobe.club/api/v1'

  if (!apiKey) {
    throw new Error('CLAUDE_API_KEY is not configured. Please add it to your environment variables.')
  }

  console.log('âœ“ Using CLAUDE_API_KEY:', apiKey.substring(0, 10) + '...')

  const client = new OpenAI({
    apiKey: apiKey,
    baseURL: baseUrl,
  })

  // é»˜è®¤ä½¿ç”¨Claude Sonnet
  const model = options?.model || 'claude-sonnet-4-5-20250929'

  // é™åˆ¶å†…å®¹é•¿åº¦ï¼Œé¿å…è¶…è¿‡API tokené™åˆ¶
  // ä¼°ç®—ï¼š200k chars â‰ˆ 100-130k tokens (å–å†³äºè¯­è¨€æ··åˆæ¯”ä¾‹)
  // åŠ ä¸Špromptæœ¬èº«çº¦5-10k tokensï¼Œæ€»å…±ä¸ä¼šè¶…è¿‡150k tokens
  const MAX_CONTENT_LENGTH = 200000 // characters
  let processedContent = content

  if (content.length > MAX_CONTENT_LENGTH) {
    console.warn(`âš ï¸  Resume content too long (${content.length} chars), truncating to ${MAX_CONTENT_LENGTH} chars`)
    processedContent = content.substring(0, MAX_CONTENT_LENGTH) + '\n\n[Content truncated due to length limit]'
  }

  const prompt = PARSE_PROMPT.replace('{CONTENT}', processedContent)

  console.log('ğŸ” Parsing resume with AI...')
  console.log(`ğŸ“Š Using model: ${model}`)
  console.log(`ğŸ“ Content length: ${processedContent.length} chars`)

  const response = await client.chat.completions.create({
    model,
    messages: [
      {
        role: 'user',
        content: prompt,
      },
    ],
    temperature: 0.1, // ä½æ¸©åº¦ç¡®ä¿ç¨³å®šè¾“å‡º
    max_tokens: 8000,
  })

  const responseText = response.choices[0]?.message?.content || ''
  console.log(`ğŸ“ AI response length: ${responseText.length}`)

  // å°è¯•è§£æJSON
  try {
    const { parseJsonFromAI } = await import('@/lib/json-utils')
    const parsed = parseJsonFromAI<ParsedResumeData>(responseText)
    console.log('âœ… Successfully parsed resume data')

    // éªŒè¯å’Œæ¸…ç†æ•°æ®
    return sanitizeParsedData(parsed)
  } catch (error) {
    console.error('âŒ Failed to parse AI response:', error)
    console.error('Response text preview:', responseText.substring(0, 500))

    // å°è¯•ä¿®å¤å¸¸è§JSONé—®é¢˜
    try {
      const { tryFixJson } = await import('@/lib/json-utils')
      const fixedJson = tryFixJson(responseText)
      const parsed = JSON.parse(fixedJson) as ParsedResumeData
      console.log('âœ… Successfully parsed resume data after fix')
      return sanitizeParsedData(parsed)
    } catch {
      console.error('âŒ Failed to fix JSON')
      // è¿”å›ç©ºç»“æ„
      return getEmptyParsedData()
    }
  }
}

/**
 * å°è¯•ä¿®å¤å¸¸è§çš„JSONæ ¼å¼é—®é¢˜
 */
// Local fixer removed; using shared tryFixJson from json-utils

/**
 * æ¸…ç†å’ŒéªŒè¯è§£æçš„æ•°æ®
 */
function sanitizeParsedData(data: ParsedResumeData): ParsedResumeData {
  // ç¡®ä¿æ‰€æœ‰å¿…éœ€çš„å­—æ®µå­˜åœ¨
  return {
    personal_info: {
      full_name: data.personal_info?.full_name || '',
      email: data.personal_info?.email || '',
      phone: data.personal_info?.phone,
      location: data.personal_info?.location,
      linkedin_url: data.personal_info?.linkedin_url,
      github_url: data.personal_info?.github_url,
      website_url: data.personal_info?.website_url,
      professional_summary: data.personal_info?.professional_summary,
    },
    work_experiences: (data.work_experiences || []).map((w) => ({
      company: w.company || '',
      position: w.position || '',
      location: w.location,
      start_date: formatDate(w.start_date) || '',
      end_date: w.end_date ? formatDate(w.end_date) : undefined,
      is_current: w.is_current || false,
      description: w.description,
      achievements: ensureArray(w.achievements),
      technologies: ensureArray(w.technologies),
    })),
    education: (data.education || []).map((e) => ({
      institution: e.institution || '',
      degree: e.degree || '',
      major: e.major || '',
      location: e.location,
      start_date: formatDate(e.start_date) || '',
      end_date: e.end_date ? formatDate(e.end_date) : undefined,
      is_current: e.is_current || false,
      gpa: e.gpa,
      achievements: ensureArray(e.achievements),
    })),
    skills: (data.skills || []).map((s) => ({
      name: s.name || '',
      level: validateSkillLevel(s.level),
      category: s.category,
    })),
    projects: (data.projects || []).map((p) => ({
      name: p.name || '',
      description: p.description || '',
      role: p.role,
      start_date: p.start_date ? formatDate(p.start_date) : undefined,
      end_date: p.end_date ? formatDate(p.end_date) : undefined,
      technologies: ensureArray(p.technologies),
      highlights: ensureArray(p.highlights),
      url: p.url,
      github_url: p.github_url,
    })),
    certifications: (data.certifications || []).map((c) => ({
      name: c.name || '',
      issuer: c.issuer || '',
      issue_date: formatDate(c.issue_date) || '',
      expiry_date: c.expiry_date ? formatDate(c.expiry_date) : undefined,
      credential_id: c.credential_id,
      credential_url: c.credential_url,
    })),
  }
}

/**
 * æ ¼å¼åŒ–æ—¥æœŸä¸º YYYY-MM-DD
 */
function formatDate(date?: string): string | undefined {
  if (!date) return undefined

  // å¦‚æœå·²ç»æ˜¯YYYY-MM-DDæ ¼å¼
  if (/^\d{4}-\d{2}-\d{2}$/.test(date)) {
    return date
  }

  // å¦‚æœåªæœ‰å¹´ä»½
  if (/^\d{4}$/.test(date)) {
    return `${date}-01-01`
  }

  // å°è¯•è§£æå…¶ä»–æ ¼å¼
  try {
    const parsed = new Date(date)
    if (!isNaN(parsed.getTime())) {
      return parsed.toISOString().split('T')[0]
    }
  } catch {
    // å¿½ç•¥è§£æé”™è¯¯
  }

  return date
}

/**
 * ç¡®ä¿å€¼æ˜¯æ•°ç»„
 */
function ensureArray(value: unknown): string[] {
  if (Array.isArray(value)) {
    return value.filter((v) => typeof v === 'string')
  }
  if (typeof value === 'string' && value) {
    return [value]
  }
  return []
}

/**
 * éªŒè¯æŠ€èƒ½ç­‰çº§
 */
function validateSkillLevel(level?: string): SkillLevel | undefined {
  const validLevels: SkillLevel[] = ['beginner', 'intermediate', 'advanced', 'expert']
  if (level && validLevels.includes(level as SkillLevel)) {
    return level as SkillLevel
  }
  return undefined
}

/**
 * è·å–ç©ºçš„è§£ææ•°æ®ç»“æ„
 */
function getEmptyParsedData(): ParsedResumeData {
  return {
    personal_info: {
      full_name: '',
      email: '',
    },
    work_experiences: [],
    education: [],
    skills: [],
    projects: [],
    certifications: [],
  }
}

/**
 * æ¸…ç†PDFæå–çš„æ–‡æœ¬
 * - å»é™¤é‡å¤è¡Œ
 * - å»é™¤è¿‡çŸ­çš„è¡Œï¼ˆ<3å­—ç¬¦ï¼‰
 * - å»é™¤å¤šä½™ç©ºç™½
 * - åˆå¹¶è¿ç»­ç©ºè¡Œ
 */
function cleanPDFText(text: string): string {
  const lines = text.split('\n')
  const seenLines = new Set<string>()
  const cleanedLines: string[] = []

  for (const rawLine of lines) {
    // æ¸…ç†ç©ºç™½å­—ç¬¦
    const line = rawLine.trim()

    // è·³è¿‡ç©ºè¡Œã€è¿‡çŸ­çš„è¡Œï¼ˆå¯èƒ½æ˜¯æ ¼å¼å­—ç¬¦ï¼‰
    if (line.length < 3) continue

    // è·³è¿‡çº¯æ•°å­—è¡Œï¼ˆå¯èƒ½æ˜¯é¡µç ï¼‰
    if (/^\d+$/.test(line)) continue

    // å»é™¤é‡å¤è¡Œï¼ˆå¸¸è§äºPDFæ ¼å¼é—®é¢˜ï¼‰
    const normalizedLine = line.toLowerCase()
    if (seenLines.has(normalizedLine)) continue

    seenLines.add(normalizedLine)
    cleanedLines.push(line)
  }

  // åˆå¹¶æˆæ–‡æœ¬ï¼Œä¿ç•™æ®µè½ç»“æ„
  return cleanedLines.join('\n')
}

/**
 * ä»PDF Bufferæå–æ–‡æœ¬
 */
export async function extractTextFromPDF(buffer: Buffer): Promise<string> {
  // åŠ¨æ€å¯¼å…¥pdf-parseä»¥é¿å…æ‰“åŒ…é—®é¢˜
  try {
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    const pdfParseModule = await import('pdf-parse') as any
    const pdfParse = pdfParseModule.default || pdfParseModule
    const data = await pdfParse(buffer)

    console.log(`ğŸ“„ Raw PDF text length: ${data.text.length} chars`)

    // æ¸…ç†æå–çš„æ–‡æœ¬
    const cleanedText = cleanPDFText(data.text)

    console.log(`ğŸ§¹ Cleaned PDF text length: ${cleanedText.length} chars (reduced ${((1 - cleanedText.length / data.text.length) * 100).toFixed(1)}%)`)

    return cleanedText
  } catch (error) {
    console.error('PDF parsing error:', error)
    // å›é€€æ–¹æ¡ˆï¼šå°è¯•æå–å¯è¯»æ–‡æœ¬
    const text = buffer.toString('utf-8')
    const cleanText = text.replace(/[^\x20-\x7E\n\r\t\u4e00-\u9fff]/g, ' ')
    return cleanText.trim()
  }
}

/**
 * æå–æ–‡ä»¶å†…å®¹ä¸ºæ–‡æœ¬
 */
export async function extractFileContent(
  file: Buffer,
  fileType: 'pdf' | 'docx' | 'doc' | 'txt'
): Promise<string> {
  switch (fileType) {
    case 'txt':
      return file.toString('utf-8')
    case 'pdf':
      return extractTextFromPDF(file)
    case 'docx':
    case 'doc':
      // Wordæ–‡æ¡£å¯ä»¥ä½¿ç”¨mammothåº“ï¼Œè¿™é‡Œç®€åŒ–å¤„ç†
      try {
        const mammoth = (await import('mammoth')).default
        const result = await mammoth.extractRawText({ buffer: file })
        return result.value
      } catch (error) {
        console.error('Word parsing error:', error)
        return file.toString('utf-8')
      }
    default:
      throw new Error(`Unsupported file type: ${fileType}`)
  }
}
